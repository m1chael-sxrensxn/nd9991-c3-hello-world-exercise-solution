version: 2.1

orbs:
  aws-cli: circleci/aws-cli@2.0.3

commands:

  destroy_environment:
    steps:
      - run:
          name: Destroy Environment
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7}

# Define the jobs we want to run for this project
jobs:
  create_infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
              --template-file template.yml \
              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:7} \
              --region us-east-1

  create_stack_inventory:
    docker:
      - image: amazon/aws-cli
    steps:
      - run:
          name: Install tar utilities
          command: yum install -y tar gzip
      - run:
          name: create inventory file
          command: |
            echo "[all]" > ~/inventory.txt && \
            aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:Project,Values=ND9991" \
              --output text >> ~/inventory.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - inventory.txt

  configure_infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - attach_workspace:
          at: ~/
      - checkout
      - add_ssh_keys:
          fingerprints: ["94:73:c0:34:7d:22:1d:89:cd:61:4f:ab:79:e1:40:2b"]
      - run:
          name: Install Ansible
          command: apk add --update ansible
      - run:
          name: Run Playbook and Configure server
          command: ansible-playbook -i ~/inventory.txt main-remote.yml

  smoke_test:
    docker:
      - image: amazon/aws-cli
    steps:
      - run:
          name: Install tar utilities
          command: yum install -y tar gzip
      - run:
          name: Install curl
          command: yum install -y curl
      - attach_workspace:
          at: ~/
      - run:
          name: smoke test
          command: |
            export IP=$(tail -n 1 ~/inventory.txt)
            export response=$(curl $IP:3000)
            if [ "$response" != 'Hello world!' ]; then
              return 1
            fi
      - destroy_environment

  ## Jobs for deploying static files
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mss-nd9991-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync ./static s3://mss-nd9991-${CIRCLE_WORKFLOW_ID:0:7} --delete

  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - textfile.txt

  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mss-nd9991-${CIRCLE_WORKFLOW_ID:0:7}"

  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack.
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive
            aws s3 rb "s3://${OldBucketID}" --force

# Sequential workflow
workflows:
  # Name the workflow
  deploy_and_intengration_test:
    jobs:
      - create_infrastructure
      - create_stack_inventory:
          requires:
            - create_infrastructure
      - configure_infrastructure:
          requires:
            - create_stack_inventory
      - smoke_test:
          requires:
            - configure_infrastructure

  deploy_static_files:
    jobs:
      - create_and_deploy_front_end
      - get_last_deployment_id
      - promote_to_production:
          requires:
            - create_and_deploy_front_end
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
